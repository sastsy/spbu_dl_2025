{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:35.316187Z",
     "iopub.status.busy": "2025-11-28T18:07:35.315434Z",
     "iopub.status.idle": "2025-11-28T18:07:35.321018Z",
     "shell.execute_reply": "2025-11-28T18:07:35.320288Z",
     "shell.execute_reply.started": "2025-11-28T18:07:35.316153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:35.468516Z",
     "iopub.status.busy": "2025-11-28T18:07:35.468036Z",
     "iopub.status.idle": "2025-11-28T18:07:35.472809Z",
     "shell.execute_reply": "2025-11-28T18:07:35.472034Z",
     "shell.execute_reply.started": "2025-11-28T18:07:35.468497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'train_dir': '/kaggle/input/one-piece-classification-2025/splitted/',\n",
    "    'test_dir': '/kaggle/input/one-piece-classification-2025/splitted/test',\n",
    "    'labels_json': '/kaggle/input/one-piece-classification-2025/labels.json',\n",
    "    'train_annotations': '/kaggle/input/one-piece-classification-2025/train_annotations.csv',\n",
    "    'submission_csv': '/kaggle/input/one-piece-classification-2025/submission.csv',\n",
    "    'output_dir': '/kaggle/working/',\n",
    "    'backbone_name': 'facebook/vit-mae-base',\n",
    "    'img_size': 224,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 1e-3,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 4,\n",
    "    'validation_split': 0.2,\n",
    "    'random_seed': 42,\n",
    "    'classifier_hidden': 512,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:35.619222Z",
     "iopub.status.busy": "2025-11-28T18:07:35.619021Z",
     "iopub.status.idle": "2025-11-28T18:07:35.624098Z",
     "shell.execute_reply": "2025-11-28T18:07:35.623278Z",
     "shell.execute_reply.started": "2025-11-28T18:07:35.619207Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(CONFIG['random_seed'])\n",
    "np.random.seed(CONFIG['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:35.774492Z",
     "iopub.status.busy": "2025-11-28T18:07:35.774291Z",
     "iopub.status.idle": "2025-11-28T18:07:35.794142Z",
     "shell.execute_reply": "2025-11-28T18:07:35.793663Z",
     "shell.execute_reply.started": "2025-11-28T18:07:35.774477Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(CONFIG['labels_json'], 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "train_df = pd.read_csv(CONFIG['train_annotations'])\n",
    "submission_df = pd.read_csv(CONFIG['submission_csv'])\n",
    "\n",
    "id_to_name = {int(k): v for k, v in label_map.items()}\n",
    "name_to_id = {v: int(k) for k, v in label_map.items()}\n",
    "num_classes = len(id_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:35.925233Z",
     "iopub.status.busy": "2025-11-28T18:07:35.924620Z",
     "iopub.status.idle": "2025-11-28T18:07:35.931794Z",
     "shell.execute_reply": "2025-11-28T18:07:35.931008Z",
     "shell.execute_reply.started": "2025-11-28T18:07:35.925212Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fix_path(x, root):\n",
    "    x = x.replace(\"\\\\\", \"/\")\n",
    "    return f\"{root}{x}\"\n",
    "\n",
    "\n",
    "train_df[\"file_path\"] = train_df[\"image_path\"].apply(\n",
    "    lambda x: fix_path(x, CONFIG[\"train_dir\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:15:30.504619Z",
     "iopub.status.busy": "2025-11-28T19:15:30.503846Z",
     "iopub.status.idle": "2025-11-28T19:15:30.511396Z",
     "shell.execute_reply": "2025-11-28T19:15:30.510696Z",
     "shell.execute_reply.started": "2025-11-28T19:15:30.504570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CharacterDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, augment_transforms=None, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.augment_transforms = augment_transforms\n",
    "        self.is_test = is_test\n",
    "        self.extensions = [\"png\", \"jpg\", \"jpeg\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _resolve_path(self, base_path_without_ext):\n",
    "        for ext in self.extensions:\n",
    "            candidate = f\"{base_path_without_ext}.{ext}\"\n",
    "            if os.path.exists(candidate):\n",
    "                return candidate\n",
    "        raise FileNotFoundError(f\"No image found for {base_path_without_ext}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        if self.is_test:\n",
    "            base = os.path.join(self.img_dir, str(row['id']))\n",
    "        else:\n",
    "            base = os.path.splitext(row['file_path'])[0]\n",
    "        img_path = self._resolve_path(base)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "        image = self.augment_transforms(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            return image, row['id']\n",
    "        else:\n",
    "            label = int(row['label'])\n",
    "            return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:36.223000Z",
     "iopub.status.busy": "2025-11-28T18:07:36.222781Z",
     "iopub.status.idle": "2025-11-28T18:07:36.227479Z",
     "shell.execute_reply": "2025-11-28T18:07:36.226805Z",
     "shell.execute_reply.started": "2025-11-28T18:07:36.222984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_aug = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.RandomResizedCrop(CONFIG['img_size'], scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "])\n",
    "val_aug = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:07:44.046350Z",
     "iopub.status.busy": "2025-11-28T19:07:44.045731Z",
     "iopub.status.idle": "2025-11-28T19:07:44.052373Z",
     "shell.execute_reply": "2025-11-28T19:07:44.051650Z",
     "shell.execute_reply.started": "2025-11-28T19:07:44.046308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ProcessorCollator:\n",
    "    def __init__(self, processor, is_test=False):\n",
    "        self.processor = processor\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        images = [item[0] for item in batch]\n",
    "        targets = [item[1] for item in batch]\n",
    "        processed = self.processor(images=images, return_tensors='pt')\n",
    "        pixel_values = processed['pixel_values']\n",
    "        if self.is_test:\n",
    "            return pixel_values, targets\n",
    "        else:\n",
    "            return pixel_values, torch.tensor(targets, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:36.829744Z",
     "iopub.status.busy": "2025-11-28T18:07:36.829124Z",
     "iopub.status.idle": "2025-11-28T18:07:36.834776Z",
     "shell.execute_reply": "2025-11-28T18:07:36.834107Z",
     "shell.execute_reply.started": "2025-11-28T18:07:36.829720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MAEClassifier(nn.Module):\n",
    "    def __init__(self, backbone_model, feat_dim, num_classes, classifier_hidden=None):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone_model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(feat_dim, classifier_hidden),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(classifier_hidden, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values, return_feats=False):\n",
    "        outputs = self.backbone(pixel_values=pixel_values, return_dict=True)\n",
    "        patches = outputs.last_hidden_state[:, 1:, :]\n",
    "        emb = patches.mean(dim=1)\n",
    "        logits = self.classifier(emb)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:11:13.635927Z",
     "iopub.status.busy": "2025-11-28T18:11:13.635614Z",
     "iopub.status.idle": "2025-11-28T18:11:13.644622Z",
     "shell.execute_reply": "2025-11-28T18:11:13.643771Z",
     "shell.execute_reply.started": "2025-11-28T18:11:13.635883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, backbone, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc='Train', leave=False)\n",
    "    for pixel_values, labels in pbar:\n",
    "        pixel_values = pixel_values.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(pixel_values)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        pbar.set_postfix({'loss': running_loss / (len(pbar)), 'acc': 100. * correct / total})\n",
    "\n",
    "    return running_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Val ', leave=False)\n",
    "        for pixel_values, labels in pbar:\n",
    "            pixel_values = pixel_values.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            pbar.set_postfix({'loss': running_loss / (len(pbar)), 'acc': 100. * correct / total})\n",
    "\n",
    "    return running_loss / len(val_loader), 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:11:15.143793Z",
     "iopub.status.busy": "2025-11-28T18:11:15.143494Z",
     "iopub.status.idle": "2025-11-28T18:11:15.155058Z",
     "shell.execute_reply": "2025-11-28T18:11:15.154255Z",
     "shell.execute_reply.started": "2025-11-28T18:11:15.143768Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2332, Val samples: 584\n"
     ]
    }
   ],
   "source": [
    "train_data_df, val_data_df = train_test_split(\n",
    "    train_df,\n",
    "    test_size=CONFIG['validation_split'],\n",
    "    random_state=CONFIG['random_seed'],\n",
    "    stratify=train_df['label']\n",
    ")\n",
    "print(f\"Train samples: {len(train_data_df)}, Val samples: {len(val_data_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:07:38.958305Z",
     "iopub.status.busy": "2025-11-28T18:07:38.958056Z",
     "iopub.status.idle": "2025-11-28T18:07:59.545387Z",
     "shell.execute_reply": "2025-11-28T18:07:59.544748Z",
     "shell.execute_reply.started": "2025-11-28T18:07:38.958285Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTMAEModel(\n",
       "  (embeddings): ViTMAEEmbeddings(\n",
       "    (patch_embeddings): ViTMAEPatchEmbeddings(\n",
       "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "  )\n",
       "  (encoder): ViTMAEEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x ViTMAELayer(\n",
       "        (attention): ViTMAEAttention(\n",
       "          (attention): ViTMAESelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (output): ViTMAESelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): ViTMAEIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): ViTMAEOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(CONFIG['backbone_name'])\n",
    "backbone = AutoModel.from_pretrained(CONFIG['backbone_name'])\n",
    "backbone.to(CONFIG['device'])\n",
    "backbone.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:15:38.238520Z",
     "iopub.status.busy": "2025-11-28T19:15:38.237836Z",
     "iopub.status.idle": "2025-11-28T19:15:38.244811Z",
     "shell.execute_reply": "2025-11-28T19:15:38.244253Z",
     "shell.execute_reply.started": "2025-11-28T19:15:38.238496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = CharacterDataset(train_data_df, CONFIG['train_dir'], augment_transforms=train_aug, is_test=False)\n",
    "val_dataset = CharacterDataset(val_data_df, CONFIG['train_dir'], augment_transforms=val_aug, is_test=False)\n",
    "test_dataset = CharacterDataset(submission_df, CONFIG['test_dir'], augment_transforms=val_aug, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:15:38.438150Z",
     "iopub.status.busy": "2025-11-28T19:15:38.437621Z",
     "iopub.status.idle": "2025-11-28T19:15:38.441750Z",
     "shell.execute_reply": "2025-11-28T19:15:38.440956Z",
     "shell.execute_reply.started": "2025-11-28T19:15:38.438130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_collator = ProcessorCollator(processor, is_test=False)\n",
    "val_collator = ProcessorCollator(processor, is_test=False)\n",
    "test_collator = ProcessorCollator(processor, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:15:38.662416Z",
     "iopub.status.busy": "2025-11-28T19:15:38.662166Z",
     "iopub.status.idle": "2025-11-28T19:15:38.667984Z",
     "shell.execute_reply": "2025-11-28T19:15:38.667132Z",
     "shell.execute_reply.started": "2025-11-28T19:15:38.662397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=CONFIG['num_workers'],\n",
    "    collate_fn=train_collator, pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=CONFIG['num_workers'],\n",
    "    collate_fn=val_collator, pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=CONFIG['num_workers'],\n",
    "    collate_fn=test_collator, pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:11:18.592553Z",
     "iopub.status.busy": "2025-11-28T18:11:18.592009Z",
     "iopub.status.idle": "2025-11-28T18:11:18.603617Z",
     "shell.execute_reply": "2025-11-28T18:11:18.602614Z",
     "shell.execute_reply.started": "2025-11-28T18:11:18.592528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = MAEClassifier(\n",
    "    backbone_model=backbone, feat_dim=768, num_classes=num_classes,\n",
    "    classifier_hidden=CONFIG['classifier_hidden']).to(CONFIG['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:11:18.937647Z",
     "iopub.status.busy": "2025-11-28T18:11:18.937365Z",
     "iopub.status.idle": "2025-11-28T18:11:18.942242Z",
     "shell.execute_reply": "2025-11-28T18:11:18.941532Z",
     "shell.execute_reply.started": "2025-11-28T18:11:18.937623Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.backbone.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T18:47:03.587478Z",
     "iopub.status.busy": "2025-11-28T18:47:03.587166Z",
     "iopub.status.idle": "2025-11-28T18:53:53.619157Z",
     "shell.execute_reply": "2025-11-28T18:53:53.618271Z",
     "shell.execute_reply.started": "2025-11-28T18:47:03.587452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3668, Train Acc: 87.86%\n",
      "Val Loss: 0.9385, Val   Acc: 71.23%\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3091, Train Acc: 90.44%\n",
      "Val Loss: 0.9727, Val   Acc: 74.14%\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3339, Train Acc: 89.28%\n",
      "Val Loss: 0.9936, Val   Acc: 71.06%\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3076, Train Acc: 90.48%\n",
      "Val Loss: 0.9577, Val   Acc: 72.43%\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3251, Train Acc: 89.97%\n",
      "Val Loss: 0.9973, Val   Acc: 72.43%\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3343, Train Acc: 89.79%\n",
      "Val Loss: 0.9551, Val   Acc: 72.60%\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3131, Train Acc: 90.14%\n",
      "Val Loss: 1.0382, Val   Acc: 72.77%\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3187, Train Acc: 89.62%\n",
      "Val Loss: 0.9273, Val   Acc: 73.80%\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2931, Train Acc: 91.42%\n",
      "Val Loss: 1.0634, Val   Acc: 71.40%\n",
      "\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3097, Train Acc: 90.01%\n",
      "Val Loss: 0.9955, Val   Acc: 73.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "params = model.classifier.parameters()\n",
    "optimizer = torch.optim.AdamW(params, lr=CONFIG['learning_rate'])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_val_acc = 0.0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    print(f\"\\nEpoch {epoch+1}/{CONFIG['epochs']}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, backbone, train_loader, optimizer, criterion, CONFIG['device'])\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, CONFIG['device'])\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val   Acc: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T19:18:10.736406Z",
     "iopub.status.busy": "2025-11-28T19:18:10.736096Z",
     "iopub.status.idle": "2025-11-28T19:18:16.689930Z",
     "shell.execute_reply": "2025-11-28T19:18:16.689124Z",
     "shell.execute_reply.started": "2025-11-28T19:18:10.736378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|██████████| 27/27 [00:05<00:00,  4.55it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_ids = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for pixel_values, ids in tqdm(test_loader, desc='Predict'):\n",
    "        pixel_values = pixel_values.to(CONFIG['device'])\n",
    "        logits = model(pixel_values)\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        all_ids.extend(ids)\n",
    "        all_preds.extend(preds.cpu().numpy().tolist())\n",
    "\n",
    "submission = pd.DataFrame({'id': all_ids, 'label': all_preds})\n",
    "submission_path = os.path.join(CONFIG['output_dir'], 'submission.csv')\n",
    "submission.to_csv(submission_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14342975,
     "sourceId": 119869,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
